# 昇思MindSpore技术公开课大模型专题第二期

昇思MindSpore技术公开课大模型专题（第二期）开课啦！

第二期课程在第一期基础上做了全面的升级，对第一期课程意犹未尽的小伙伴可以来继续一起学习大模型啦，也非常欢迎新的小伙伴加入！

学术圈、企业、优秀开发者等各领域大咖讲师齐聚MindSpore为各位开发者教学，课程全程免费，对大模型领域感兴趣的小伙伴速速报名啦！

## 课程总览

<div align="center"><img src="./assets/course_introduction.jpg" alt="course-introduction"></div>

## 课程安排

> 因为课程周期较长，课节安排可能会在中途出现微调，以最终授课情况为准，感谢理解

***【课前学习】 MindSpore Transformers大模型套件：架构讲解与使用入门***

介绍MindSpore Transformers大模型套件现状，讲解套件架构及高阶接口设计，走读工程架构模块代码，学习基本使用方式

[link](https://www.bilibili.com/video/BV1jh4y1m7xV/?spm_id_from=333.999.0.0)


***第一讲：ChatGLM***

介绍技术公开课整体课程安排；ChatGLM模型结构，走读代码演示ChatGLM推理部署


***第二讲：多模态遥感智能解译基础模型***

介绍多模态遥感智能解译基础模型的原理、训推等相关技术，以及模型相关行业应用

***第三讲：ChatGLM2***

介绍ChatGLM2模型结构，走读代码演示ChatGLM推理部署

***第四讲：文本生成解码原理***

介绍Beam search和采样的原理及代码实现

***第五讲：LLAMA***

介绍LLAMA模型结构，走读代码演示推理部署，介绍Alpaca

***第六讲：LLAMA2***

介绍LLAMA2模型结构，走读代码演示LLAMA2 chat部署

***第七讲：云从大模型***

***第八讲：MOE***

***第九讲：CPM***

介绍CPM-Bee预训练、推理、微调及代码现场演示

***第十讲：高效参数微调***

介绍Lora、（P-Tuning）原理及代码实现

***第十一讲：参数微调平台***

***第十二讲：Prompt Engineering***

***第十三讲：量化***

介绍低比特量化等相关模型量化技术

***第十四讲：框架LangChain模块解析***

解析Models、Prompts、Memory、Chains、Agents、Indexes、Callbacks模块，及案例分析

***第十五讲：LangChain对话机器人综合案例***

MindSpore Transformers本地模型与LangChain框架组合使用，通过LangChain框架管理向量库并基于向量库对MindSpore Transformers本地模型问答进行优化