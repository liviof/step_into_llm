{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"./assets/cover.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"./assets/table_of_contents_1.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. 问题一：参与本次课程需要什么基础？\n",
    "\n",
    "- 了解深度学习基础知识，如损失函数、反向传播等；\n",
    "- 了解NLP相关基础知识，如word embedding，RNN层，seq2seq模型等；\n",
    "\n",
    "<div align=\"center\"><img src=\"./assets/d2l.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. 问题二：可否提供一些课后练习？\n",
    "\n",
    "<div align=\"center\"><img src=\"./assets/course-review.png\"></div>\n",
    "\n",
    "- Transformer:\n",
    "    - 尝试使用混合精度，提升模型训练及推理速度（包括BLEU Score计算）；\n",
    "    - 尝试更换数据集进行另两种语言的机器翻译；\n",
    "- BERT\n",
    "    - 参考课程中介绍的下游任务，自己选择一种进行实践；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. 问题三：学习中遇到问题怎么办？\n",
    "\n",
    "- 课上：在直播评论区随时提问，如自己的问题未得到答复，可将问题写入共享文档中，课后/下节课正式授课前进行统一答复；\n",
    "- 课后：在QQ群进行提问，或在代码仓中提issue；\n",
    "\n",
    "<div align=\"center\"><img src=\"./assets/q_and_a.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"./assets/table_of_contents_2.png\"></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "未标注的文本数据远多于已标注的文本数据，并且对于不同的下游任务会存在不同的标注方式\n",
    "\n",
    "# Method\n",
    "\n",
    "## semi-supervised learning\n",
    "\n",
    "- 基于大量未标注的文本数据，训练预训练语言模型\n",
    "- 使用已标注文本数据，对模型针对某一特定下游任务进行finetune，只更改output layer（线性层）\n",
    "\n",
    "# Problem Statement\n",
    "\n",
    "- 自然语言处理的下游任务非常多元，难以有统一的优化目标\n",
    "- 难以将预训练模型的信息完全传递到finetune的下游任务中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unsupervised Pretraining"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## objective\n",
    "\n",
    "<div align=\"center\"><img src=\"./assets/objective.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## model architecture\n",
    "\n",
    "由于训练objective的选择，gpt在模型选择上不应该看见当前token后的信息，故模型应设计为单向网络，即transformer中的decoder结构。\n",
    "\n",
    "<div align=\"center\"><img src=\"./assets/model.png\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import mindspore\n",
    "from mindspore import nn\n",
    "from mindspore import ops\n",
    "from mindspore import Tensor\n",
    "from mindspore.common.initializer import initializer, Normal\n",
    "from mindnlp.models.gpt.gpt_config import GPTConfig\n",
    "from mindnlp._legacy.nn import Dropout\n",
    "from mindnlp.abc import PreTrainedModel\n",
    "from mindnlp.models.utils import Conv1D, prune_conv1d_layer, find_pruneable_heads_and_indices\n",
    "from mindnlp.models.utils import SequenceSummary\n",
    "from mindnlp.models.activations import ACT2FN\n",
    "from mindnlp import GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Feed-Forward 实现\n",
    "class MLP(nn.Cell):\n",
    "    r\"\"\"\n",
    "    GPT MLP\n",
    "\t\"\"\"\n",
    "\n",
    "    def __init__(self, n_state, config):\n",
    "        super().__init__()\n",
    "        n_embd = config.n_embd\n",
    "        self.c_fc = Conv1D(n_state, n_embd)\n",
    "        self.c_proj = Conv1D(n_embd, n_state)\n",
    "        self.act = ACT2FN[config.afn]\n",
    "        self.dropout = Dropout(p=config.resid_pdrop)\n",
    "\n",
    "    def construct(self, x):\n",
    "        h = self.act(self.c_fc(x))\n",
    "        h2 = self.c_proj(h)\n",
    "        return self.dropout(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Multi-head attention 实现\n",
    "\n",
    "class Attention(nn.Cell):\n",
    "    r\"\"\"\n",
    "    GPT Attention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nx, n_positions, config, scale=False):\n",
    "        super().__init__()\n",
    "        n_state = nx  # in Attention: n_state=768 (nx=n_embd)\n",
    "        # [switch nx => n_state from Block to Attention to keep identical to TF implementation]\n",
    "        if n_state % config.n_head != 0:\n",
    "            raise ValueError(f\"Attention n_state shape: {n_state} must be divisible by config.n_head {config.n_head}\")\n",
    "\n",
    "        self.bias = Tensor(np.tril(np.ones((n_positions, n_positions))), mindspore.float32).view(1, 1, n_positions, n_positions)\n",
    "        self.n_head = config.n_head\n",
    "        self.split_size = n_state\n",
    "        self.scale = scale\n",
    "\n",
    "        self.c_attn = Conv1D(n_state * 3, n_state)\n",
    "        self.c_attn = Conv1D(n_state * 3, n_state)\n",
    "        self.c_proj = Conv1D(n_state, n_state)\n",
    "        self.attn_dropout = Dropout(p=config.attn_pdrop)\n",
    "        self.resid_dropout = Dropout(p=config.resid_pdrop)\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "        self.output_attentions = config.output_attentions\n",
    "\n",
    "    def prune_heads(self, heads):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model.\n",
    "        \"\"\"\n",
    "        if len(heads) == 0:\n",
    "            return\n",
    "        head_size = self.split_size//self.n_head\n",
    "        heads, index = find_pruneable_heads_and_indices(heads, self.n_head, head_size, self.pruned_heads)\n",
    "        index_attn = ops.cat([index, index + self.split_size, index + (2 * self.split_size)])\n",
    "        # Prune conv1d layers\n",
    "        self.c_attn = prune_conv1d_layer(self.c_attn, index_attn, axis=1)\n",
    "        self.c_proj = prune_conv1d_layer(self.c_proj, index, axis=0)\n",
    "        # Update hyper params\n",
    "        self.split_size = (self.split_size // self.n_head) * (self.n_head - len(heads))\n",
    "        self.n_head = self.n_head - len(heads)\n",
    "        self.pruned_heads = self.pruned_heads.union(heads)\n",
    "\n",
    "    def _attn(self, q, k, v, attention_mask=None, head_mask=None):\n",
    "        w = ops.matmul(q, k)\n",
    "        if self.scale:\n",
    "            w = w / ops.sqrt(ops.scalar_to_tensor(v.shape[-1]))\n",
    "        b = self.bias[:, :, : w.shape[-2], : w.shape[-1]]\n",
    "        w = w * b + -1e9 * (1 - b)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            w = w + attention_mask\n",
    "\n",
    "        w = ops.softmax(w)\n",
    "        w = self.attn_dropout(w)\n",
    "\n",
    "        if head_mask is not None:\n",
    "            w = w * head_mask\n",
    "\n",
    "        outputs = (ops.matmul(w, v),)\n",
    "        if self.output_attentions:\n",
    "            outputs += (w,)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def merge_heads(self, x):\n",
    "        \"\"\"merge heads\"\"\"\n",
    "        x = x.transpose(0, 2, 1, 3)\n",
    "        new_x_shape = x.shape[:-2] + (x.shape[-2] * x.shape[-1],)\n",
    "        return x.view(new_x_shape)\n",
    "\n",
    "    def split_heads(self, x, k=False):\n",
    "        \"\"\"split heads\"\"\"\n",
    "        new_x_shape = x.shape[:-1] + (self.n_head, x.shape[-1] // self.n_head)\n",
    "        x = x.view(new_x_shape)\n",
    "        if k:\n",
    "            return x.transpose(0, 2, 3, 1)\n",
    "        return x.transpose(0, 2, 1, 3)\n",
    "\n",
    "    def construct(self, x, attention_mask=None, head_mask=None):\n",
    "        x = self.c_attn(x)\n",
    "        query, key, value = ops.split(x, self.split_size, axis=2)\n",
    "        query = self.split_heads(query)\n",
    "        key = self.split_heads(key, k=True)\n",
    "        value = self.split_heads(value)\n",
    "\n",
    "        attn_outputs = self._attn(query, key, value, attention_mask, head_mask)\n",
    "        a = attn_outputs[0]\n",
    "\n",
    "        a = self.merge_heads(a)\n",
    "        a = self.c_proj(a)\n",
    "        a = self.resid_dropout(a)\n",
    "        outputs = (a,) + attn_outputs[1:]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# transformer decoder block实现\n",
    "class Block(nn.Cell):\n",
    "    r\"\"\"\n",
    "    GPT Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_positions, config, scale=False):\n",
    "        super().__init__()\n",
    "        nx = config.n_embd\n",
    "        self.attn = Attention(nx, n_positions, config, scale)\n",
    "        self.ln_1 = nn.LayerNorm((nx,), epsilon=config.layer_norm_epsilon)\n",
    "        self.mlp = MLP(4 * nx, config)\n",
    "        self.ln_2 = nn.LayerNorm((nx,), epsilon=config.layer_norm_epsilon)\n",
    "\n",
    "    def construct(self, x, attention_mask=None, head_mask=None):\n",
    "        output_attn = self.attn(\n",
    "            x,\n",
    "            attention_mask=attention_mask,\n",
    "            head_mask=head_mask\n",
    "        )\n",
    "\n",
    "        a = output_attn[0]\n",
    "        n = self.ln_1(x + a)\n",
    "        m = self.mlp(n)\n",
    "        h = self.ln_2(n + m)\n",
    "\n",
    "        outputs = (h,) + output_attn[1:]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# GPT pretrained model实现\n",
    "class GPTPreTrainedModel(PreTrainedModel):\n",
    "    \"\"\"BertPretrainedModel\"\"\"\n",
    "    convert_torch_to_mindspore = torch_to_mindspore\n",
    "    pretrained_model_archive_map = PRETRAINED_MODEL_ARCHIVE_MAP\n",
    "    config_class = GPTConfig\n",
    "    base_model_prefix = 'transformer'\n",
    "\n",
    "    def _init_weights(self, cell):\n",
    "        \"\"\"Initialize the weights\"\"\"\n",
    "        if isinstance(cell, nn.Dense):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            cell.weight.set_data(initializer(Normal(self.config.initializer_range),\n",
    "                                                    cell.weight.shape, cell.weight.dtype))\n",
    "            if cell.has_bias:\n",
    "                cell.bias.set_data(initializer('zeros', cell.bias.shape, cell.bias.dtype))\n",
    "        elif isinstance(cell, nn.Embedding):\n",
    "            embedding_table = initializer(Normal(self.config.initializer_range),\n",
    "                                                 cell.embedding_table.shape,\n",
    "                                                 cell.embedding_table.dtype)\n",
    "            if cell.padding_idx is not None:\n",
    "                embedding_table[cell.padding_idx] = 0\n",
    "            cell.embedding_table.set_data(embedding_table)\n",
    "        elif isinstance(cell, nn.LayerNorm):\n",
    "            cell.gamma.set_data(initializer('ones', cell.gamma.shape, cell.gamma.dtype))\n",
    "            cell.beta.set_data(initializer('zeros', cell.beta.shape, cell.beta.dtype))\n",
    "\n",
    "class GPTModel(GPTPreTrainedModel):\n",
    "    \"\"\"\n",
    "    The bare GPT transformer model outputting raw hidden-states without any specific head on top\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.tokens_embed = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "        self.positions_embed = nn.Embedding(config.n_positions, config.n_embd)\n",
    "        self.drop = nn.Dropout(p=config.embd_pdrop)\n",
    "        self.h = nn.CellList([Block(config.n_positions, config, scale=True) for _ in range(config.n_layer)])\n",
    "        self.position_ids = ops.arange(config.n_positions)\n",
    "\n",
    "        self.n_layer = self.config.n_layer\n",
    "        self.output_attentions = self.config.output_attentions\n",
    "        self.output_hidden_states = self.config.output_hidden_states\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        \"\"\"\n",
    "        return the input embeddings layer\n",
    "        \"\"\"\n",
    "        return self.tokens_embed\n",
    "\n",
    "    def set_input_embeddings(self, value):\n",
    "        \"\"\"\n",
    "        set the input embeddings layer\n",
    "        \"\"\"\n",
    "        self.tokens_embed = value\n",
    "\n",
    "    def _prune_heads(self, heads_to_prune):\n",
    "        \"\"\"\n",
    "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n",
    "        \"\"\"\n",
    "        for layer, heads in heads_to_prune.items():\n",
    "            self.h[layer].attn.prune_heads(heads)\n",
    "\n",
    "    def construct(\n",
    "            self,\n",
    "            input_ids=None,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            inputs_embeds=None,\n",
    "    ):\n",
    "        if input_ids is not None and inputs_embeds is not None:\n",
    "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "        if input_ids is not None:\n",
    "            input_shape = input_ids.shape\n",
    "            input_ids = input_ids.view(-1, input_shape[-1])\n",
    "        elif inputs_embeds is not None:\n",
    "            input_shape = inputs_embeds.shape[:-1]\n",
    "        else:\n",
    "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "        if position_ids is None:\n",
    "            # Code is different from when we had a single embedding matrix  from position and token embeddings\n",
    "            position_ids = self.position_ids[None, : input_shape[-1]]\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "            attention_mask = attention_mask.to(dtype=next(self.parameters()).dtype)\n",
    "            attention_mask = (1.0 - attention_mask) * Tensor(np.finfo(mindspore.dtype_to_nptype(self.dtype)).min,\n",
    "                                                             self.dtype)\n",
    "\n",
    "        # Prepare head mask if needed\n",
    "        head_mask = self.get_head_mask(head_mask, self.n_layer)\n",
    "\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.tokens_embed(input_ids)\n",
    "        position_embeds = self.positions_embed(position_ids)\n",
    "        if token_type_ids is not None:\n",
    "            token_type_ids = token_type_ids.view(-1, token_type_ids.shape[-1])\n",
    "            token_type_embeds = self.tokens_embed(token_type_ids)\n",
    "        else:\n",
    "            token_type_embeds = 0\n",
    "        hidden_states = inputs_embeds + position_embeds + token_type_embeds\n",
    "        hidden_states = self.drop(hidden_states)\n",
    "\n",
    "        output_shape = input_shape + (hidden_states.shape[-1],)\n",
    "\n",
    "        all_attentions = ()\n",
    "        all_hidden_states = ()\n",
    "        for i, block in enumerate(self.h):\n",
    "            if self.output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            outputs = block(hidden_states, attention_mask, head_mask[i])\n",
    "            hidden_states = outputs[0]\n",
    "            if self.output_attentions:\n",
    "                all_attentions = all_attentions + (outputs[1],)\n",
    "\n",
    "        hidden_states = hidden_states.view(*output_shape)\n",
    "\n",
    "        # Add last layer\n",
    "        if self.output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        return (hidden_states, all_hidden_states, all_attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"./assets/table_of_contents_3.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised Fine-Tuning\n",
    "\n",
    "在已经预训练好的GPT上额外加一层线性层\n",
    "\n",
    "<div align=\"center\"><img src=\"./assets/finetune_output.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "并通过缩小目标与计算结果的误差进行模型优化\n",
    "\n",
    "<div align=\"center\"><img src=\"./assets/finetune_objective.png\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "最终为加速模型收敛及提高模型的泛化性，融入pretrain时language modelling的优化目标\n",
    "\n",
    "<div align=\"center\"><img src=\"./assets/finetune_overall_objective.png\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 文本序列分类任务\n",
    "\n",
    "class GPTForSequenceClassification(GPTPreTrainedModel):\n",
    "    \"\"\"\n",
    "    The Original GPT Model transformer with a sequence classification head on top (linear layer).\n",
    "    GPTForSequenceClassification uses the last token in order to do the classification, as other causal\n",
    "    models (e.g. GPT-2) do. Since it does classification on the last token, it requires to know the position of the\n",
    "    last token. If a `pad_token_id` is defined in the configuration, it finds the last token that is not a padding\n",
    "    token in each row. If no `pad_token_id` is defined, it simply takes the last value in each row of the batch. Since\n",
    "    it cannot guess the padding tokens when `inputs_embeds` are passed instead of `input_ids`, it does the same (take\n",
    "    the last value in each row of the batch).\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.num_labels = config.num_labels\n",
    "        self.transformer = GPTModel(config)\n",
    "        self.score = nn.Dense(config.n_embd, self.num_labels, has_bias=False)\n",
    "\n",
    "        self.pad_token_id = self.config.pad_token_id\n",
    "        problem_type = config.problem_type\n",
    "        if problem_type is None:\n",
    "            self.loss = None\n",
    "        else:\n",
    "            if self.num_labels == 1:\n",
    "                self.problem_type = \"regression\"\n",
    "                self.loss = nn.MSELoss()\n",
    "            elif self.num_labels > 1:\n",
    "                self.problem_type = \"single_label_classification\"\n",
    "                self.loss = nn.CrossEntropyLoss()\n",
    "            else:\n",
    "                self.problem_type = \"multi_label_classification\"\n",
    "                self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def construct(\n",
    "        self,\n",
    "        input_ids = None,\n",
    "        attention_mask = None,\n",
    "        token_type_ids = None,\n",
    "        position_ids = None,\n",
    "        head_mask = None,\n",
    "        inputs_embeds = None,\n",
    "        labels = None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in\n",
    "            `[0, ...,config.num_labels - 1]`.\n",
    "            If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        transformer_outputs = self.transformer(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        hidden_states = transformer_outputs[0]\n",
    "        logits = self.score(hidden_states)\n",
    "\n",
    "        if input_ids is not None:\n",
    "            batch_size, _ = input_ids.shape[:2]\n",
    "        else:\n",
    "            batch_size, _ = inputs_embeds.shape[:2]\n",
    "\n",
    "        # Ensure the batch size is > 1 if there is no padding.\n",
    "        if self.pad_token_id is None and batch_size != 1:\n",
    "            raise ValueError(\"Cannot handle batch sizes > 1 if no padding token is defined.\")\n",
    "\n",
    "        if self.pad_token_id is None:\n",
    "            sequence_lengths = -1\n",
    "        else:\n",
    "            if input_ids is not None:\n",
    "                sequence_lengths = ops.ne(input_ids, self.pad_token_id).sum(-1) - 1\n",
    "            else:\n",
    "                sequence_lengths = -1\n",
    "\n",
    "        pooled_logits = logits[:, sequence_lengths]\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        output = (pooled_logits,) + transformer_outputs[1:]\n",
    "\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss = self.loss(pooled_logits.squeeze(), labels.squeeze())\n",
    "            elif self.num_labels > 1:\n",
    "                loss = self.loss(pooled_logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            else:\n",
    "                loss = self.loss(pooled_logits, labels)\n",
    "\n",
    "        if loss is not None:\n",
    "            output = (loss,) + output\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "rise": {
   "enable_chalkboard": true,
   "height": "110%",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
